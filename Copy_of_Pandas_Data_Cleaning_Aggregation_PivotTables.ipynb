{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MTirop/GitPractise/blob/main/Copy_of_Pandas_Data_Cleaning_Aggregation_PivotTables.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1be12683",
      "metadata": {
        "id": "1be12683"
      },
      "source": [
        "\n",
        "# Pandas for Data Cleaning, Aggregations, and Pivot Tables\n",
        "\n",
        "In this notebook, we'll cover some essential tasks in data analysis using **pandas**:\n",
        "1. Data Cleaning\n",
        "2. Aggregations\n",
        "3. Pivot Tables\n",
        "\n",
        "We'll use examples and simple datasets to demonstrate how to effectively manipulate and analyze data with pandas.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "36c78898",
      "metadata": {
        "id": "36c78898"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "07d73b3c",
      "metadata": {
        "id": "07d73b3c"
      },
      "source": [
        "\n",
        "## 1. Data Cleaning\n",
        "\n",
        "Data cleaning is the process of fixing or removing incorrect, corrupted, incorrectly formatted, duplicate, or incomplete data within a dataset.\n",
        "\n",
        "### Common Data Cleaning Tasks:\n",
        "- Missing values\n",
        "- Duplicates\n",
        "- Incorrect data types\n",
        "- Inconsistent formatting\n",
        "- Outliers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9ff146a2",
      "metadata": {
        "id": "9ff146a2",
        "outputId": "207d5eb5-eb1c-4bc5-f0c5-37c51e12dac5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'np' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-76eb526bcc7d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m data = {\n\u001b[1;32m      3\u001b[0m     \u001b[0;34m\"Name\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"Alice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Bob\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"David \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Eve\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Alice\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"FRANK\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;34m\"Age\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m22\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m35\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"50\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"City\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"New York\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Los Angeles\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"new york\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Chicago\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"New York\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"BOSTON\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;34m\"Salary\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"$50,000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$75,000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$60,000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"90000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$65,000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$50,000\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"$80000\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
          ]
        }
      ],
      "source": [
        "# Create a sample \"messy\" dataset\n",
        "data = {\n",
        "    \"Name\": [\"Alice\", \"Bob\", None, \"David \", \"Eve\", \"Alice\", \"FRANK\"],\n",
        "    \"Age\": [25, np.nan, 22, 35, 29, 25, \"50\"],\n",
        "    \"City\": [\"New York\", \"Los Angeles\", \"new york\", None, \"Chicago\", \"New York\", \"BOSTON\"],\n",
        "    \"Salary\": [\"$50,000\", \"$75,000\", \"$60,000\", \"90000\", \"$65,000\", \"$50,000\", \"$80000\"],\n",
        "    \"Join_Date\": [\"2021-01-15\", \"01/15/2020\", \"2022/03/01\", \"2019-05-20\", None, \"2021-01-15\", \"20-07-2018\"]\n",
        "}\n",
        "\n",
        "# Create DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "\n",
        "# Display the original dataset\n",
        "print(\"Original Dataset:\")\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5ae834df",
      "metadata": {
        "id": "5ae834df"
      },
      "outputs": [],
      "source": [
        "# Get a quick summary of the dataset\n",
        "print(\"Basic DataFrame information:\")\n",
        "df.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "31d7006f",
      "metadata": {
        "id": "31d7006f"
      },
      "outputs": [],
      "source": [
        "# Statistical summary (only works on numeric columns)\n",
        "print(\"\\nStatistical summary:\")\n",
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "947497ff",
      "metadata": {
        "id": "947497ff"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Check for missing values\n",
        "df.isnull()\n",
        "#df.isnull().sum()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "375ffedb",
      "metadata": {
        "id": "375ffedb"
      },
      "outputs": [],
      "source": [
        "# Approach 1: Remove rows with any missing values\n",
        "# Drop rows with missing values\n",
        "df_cleaned = df.dropna()\n",
        "df_cleaned\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4ef89fee",
      "metadata": {
        "id": "4ef89fee"
      },
      "outputs": [],
      "source": [
        "# Approach 2: Fill missing values with appropriate replacements\n",
        "df_filled = df.copy()\n",
        "\n",
        "# Fill missing names with \"Unknown\"\n",
        "df_filled[\"Name\"] = df_filled[\"Name\"].fillna(\"Unknown\")\n",
        "\n",
        "# Fill missing ages with the mean age (first convert to numeric)\n",
        "df_filled[\"Age\"] = pd.to_numeric(df_filled[\"Age\"], errors='coerce')\n",
        "mean_age = df_filled[\"Age\"].mean()\n",
        "df_filled[\"Age\"] = df_filled[\"Age\"].fillna(mean_age)\n",
        "\n",
        "# Fill missing cities with \"Unknown\"\n",
        "df_filled[\"City\"] = df_filled[\"City\"].fillna(\"Unknown\")\n",
        "\n",
        "# Fill missing dates with the most frequent date\n",
        "df_filled[\"Join_Date\"] = df_filled[\"Join_Date\"].fillna(df_filled[\"Join_Date\"].mode()[0])\n",
        "\n",
        "print(\"Dataset after filling missing values:\")\n",
        "df_filled"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "945d7f78",
      "metadata": {
        "id": "945d7f78"
      },
      "source": [
        "The errors='coerce' argument tells pandas to convert invalid parsing (e.g., non-numeric values like strings or symbols) into NaN (Not a Number) instead of throwing an error."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a18c5054",
      "metadata": {
        "id": "a18c5054"
      },
      "outputs": [],
      "source": [
        "# Check for duplicate rows\n",
        "print(f\"Number of duplicate rows: {df_filled.duplicated().sum()}\")\n",
        "\n",
        "# Show the duplicate rows\n",
        "dupes = df_filled[df_filled.duplicated()]\n",
        "print(\"\\nDuplicate rows:\")\n",
        "print(dupes)\n",
        "\n",
        "# Remove duplicates and keep the first occurrence\n",
        "df_no_dupes = df_filled.drop_duplicates()\n",
        "\n",
        "print(f\"\\nShape before removing duplicates: {df_filled.shape}\")\n",
        "print(f\"Shape after removing duplicates: {df_no_dupes.shape}\")\n",
        "df_no_dupes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bdb2b746",
      "metadata": {
        "id": "bdb2b746"
      },
      "outputs": [],
      "source": [
        "# For demonstration: You can also remove duplicates based on specific columns\n",
        "# For example, if we consider records with the same Name and Age as duplicates:\n",
        "df_no_dupes_subset = df_filled.drop_duplicates(subset=[\"Join_Date\"])\n",
        "print(f\"\\nShape after removing duplicates based on Join_Date: {df_no_dupes_subset.shape}\")\n",
        "df_no_dupes_subset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6e2c64c",
      "metadata": {
        "id": "b6e2c64c"
      },
      "outputs": [],
      "source": [
        "# Create a clean copy to work with\n",
        "df_clean = df_no_dupes.copy()\n",
        "\n",
        "# 1. Standardize text case in Name column (Title case)\n",
        "df_clean[\"Name\"] = df_clean[\"Name\"].str.strip().str.title()\n",
        "\n",
        "# 2. Standardize City names (Title case)\n",
        "df_clean[\"City\"] = df_clean[\"City\"].str.strip().str.title()\n",
        "\n",
        "# 3. Convert Age to integer\n",
        "df_clean[\"Age\"] = df_clean[\"Age\"].astype(int)\n",
        "\n",
        "# Display the updated DataFrame\n",
        "print(\"After standardizing Names and Cities:\")\n",
        "df_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3894c5cb",
      "metadata": {
        "id": "3894c5cb"
      },
      "source": [
        ".str.strip() removes leading and trailing whitespaces\n",
        "\"  alice  \" → \"alice\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "330c2998",
      "metadata": {
        "id": "330c2998"
      },
      "outputs": [],
      "source": [
        "# Convert Salary to numeric by removing $ and commas\n",
        "df_clean[\"Salary\"] = df_clean[\"Salary\"].str.replace('$', '', regex=False).str.replace(',', '', regex=False)\n",
        "df_clean[\"Salary\"] = pd.to_numeric(df_clean[\"Salary\"])\n",
        "\n",
        "# Check the data types\n",
        "print(\"DataFrame data types after conversion:\")\n",
        "df_clean.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "dc3bf5c3",
      "metadata": {
        "id": "dc3bf5c3"
      },
      "source": [
        "- str.replace() is used for string replacement.\n",
        "- regex=False tells pandas to treat the 'dollar_sign' as a literal character, not a regular expression (where 'dollar_sign' means “end of string”).\n",
        "\n",
        "Regex stands for Regular Expression.\n",
        "It’s a powerful tool used for searching, matching, and manipulating text patterns — kind of like \"smart find and replace\" on steroids. e.g.\n",
        "\n",
        "| Pattern | Meaning                                  | Example Match                                 |\n",
        "|---------|------------------------------------------|-----------------------------------------------|\n",
        "| `.`     | Any character (except newline)           | `a.b` → matches `acb`, `arb`, `a9b`           |\n",
        "| `\\d`    | Any digit (0-9)                          | `\\d\\d` → matches `23`, `45`                   |\n",
        "| `\\w`    | Any word character (a-z, A-Z, 0-9, _)    | `\\w\\w` → matches `ab`, `Z9`                   |\n",
        "| `\\s`    | Any whitespace (space, tab, etc)         |                                               |\n",
        "| `*`     | 0 or more occurrences                    | `a*` → matches `\"\"`, `a`, `aaa`               |\n",
        "| `+`     | 1 or more occurrences                    | `a+` → matches `a`, `aaaa`                    |\n",
        "| `?`     | 0 or 1 occurrence (optional)             | `a?b` → matches `b` or `ab`                   |\n",
        "| `[]`    | Any one of the characters inside         | `[aeiou]` → matches any vowel like `a`, `e`   |\n",
        "| `^`     | Start of string                          | `^Hello` → matches strings starting with \"Hello\" |\n",
        "| `$`     | End of string                            | `end$` → matches strings ending in \"end\"      |\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "dc601319",
      "metadata": {
        "id": "dc601319"
      },
      "outputs": [],
      "source": [
        "# Rename columns for better clarity\n",
        "df_clean = df_clean.rename(columns={\n",
        "    \"Name\": \"full_name\",\n",
        "    \"Age\": \"age\",\n",
        "    \"City\": \"city\",\n",
        "    \"Salary\": \"annual_salary\",\n",
        "    \"Join_Date\": \"joining_date\"\n",
        "})\n",
        "\n",
        "# Display the cleaned dataset\n",
        "print(\"Final cleaned dataset:\")\n",
        "df_clean"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e11905a6",
      "metadata": {
        "id": "e11905a6"
      },
      "source": [
        "\n",
        "## 2. Aggregations\n",
        "\n",
        "Aggregation involves performing operations like sum, mean, count, etc., on groups of data.\n",
        "\n",
        "### Useful Functions:\n",
        "- `groupby()`\n",
        "- `agg()`\n",
        "- `mean()`, `sum()`, `count()`, etc.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6c72d959",
      "metadata": {
        "id": "6c72d959"
      },
      "outputs": [],
      "source": [
        "# Create a dataset with more records for better aggregation examples\n",
        "sales_data = {\n",
        "    \"store_id\": [\"A\", \"A\", \"A\", \"B\", \"B\", \"B\", \"C\", \"C\", \"C\", \"A\", \"B\", \"C\"],\n",
        "    \"product_category\": [\"Electronics\", \"Clothing\", \"Grocery\", \"Electronics\", \"Clothing\",\n",
        "                          \"Grocery\", \"Electronics\", \"Clothing\", \"Grocery\", \"Electronics\", \"Grocery\", \"Clothing\"],\n",
        "    \"sale_date\": pd.date_range(start=\"2023-01-01\", periods=12, freq=\"D\"),\n",
        "    \"sales_amount\": [5200, 1500, 950, 4800, 1700, 1150, 3800, 1200, 880, 5500, 1250, 1350],\n",
        "    \"units_sold\": [12, 30, 45, 10, 32, 55, 8, 24, 40, 13, 58, 27],\n",
        "    \"discount_applied\": [True, False, False, True, False, True, False, True, False, True, True, False]\n",
        "}\n",
        "\n",
        "sales_df = pd.DataFrame(sales_data)\n",
        "print(\"Sample sales data:\")\n",
        "sales_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "526a6731",
      "metadata": {
        "id": "526a6731"
      },
      "outputs": [],
      "source": [
        "# Basic statistics for the entire dataset\n",
        "print(\"Overall statistics:\")\n",
        "sales_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "25951116",
      "metadata": {
        "id": "25951116"
      },
      "outputs": [],
      "source": [
        "# Sum of sales by store\n",
        "print(\"\\nTotal sales by store:\")\n",
        "sales_df.groupby(\"store_id\")[\"sales_amount\"].sum()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a9791d35",
      "metadata": {
        "id": "a9791d35"
      },
      "outputs": [],
      "source": [
        "# Average units sold by product category\n",
        "print(\"\\nAverage units sold by product category:\")\n",
        "sales_df.groupby(\"product_category\")[\"units_sold\"].mean()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "336cd91b",
      "metadata": {
        "id": "336cd91b"
      },
      "outputs": [],
      "source": [
        "# Count of sales by store and whether discount was applied\n",
        "print(\"\\nCount of sales by store and discount status:\")\n",
        "sales_df.groupby([\"store_id\", \"discount_applied\"]).size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bbe5c8b6",
      "metadata": {
        "id": "bbe5c8b6"
      },
      "outputs": [],
      "source": [
        "# Using lambda functions for quick custom aggregations\n",
        "result = sales_df.groupby(\"product_category\").agg({\n",
        "    \"sales_amount\": [\n",
        "        (\"Total\", \"sum\"),\n",
        "        (\"Average\", \"mean\"),\n",
        "        (\"Range\", lambda x: x.max() - x.min())\n",
        "    ]\n",
        "})\n",
        "\n",
        "print(\"Using lambda functions in aggregations:\")\n",
        "result"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0189c9a0",
      "metadata": {
        "id": "0189c9a0"
      },
      "source": [
        "\n",
        "## 3. Pivot Tables\n",
        "\n",
        "- Pivot tables allow you to summarize data in a tabular format based on categorical data.\n",
        "- Pivot tables reshape data to summarize information. They're similar to Excel pivot tables and help you see data from different angles.\n",
        "### Syntax:\n",
        "```python\n",
        "pd.pivot_table(data, values, index, columns, aggfunc)\n",
        "```\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb98a3c0",
      "metadata": {
        "id": "cb98a3c0"
      },
      "outputs": [],
      "source": [
        "# Create a basic pivot table: rows=store_id, columns=product_category, values=sales_amount\n",
        "pivot1 = pd.pivot_table(\n",
        "    sales_df,\n",
        "    values=\"sales_amount\",\n",
        "    index=\"store_id\",\n",
        "    columns=\"product_category\",\n",
        "    aggfunc=\"sum\"\n",
        ")\n",
        "\n",
        "print(\"Basic pivot table (sum of sales by store and product category):\")\n",
        "pivot1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7fd99a2c",
      "metadata": {
        "id": "7fd99a2c"
      },
      "outputs": [],
      "source": [
        "# Add row and column totals\n",
        "pivot_with_margins = pd.pivot_table(\n",
        "    sales_df,\n",
        "    values=\"sales_amount\",\n",
        "    index=\"store_id\",\n",
        "    columns=\"product_category\",\n",
        "    aggfunc=\"sum\",\n",
        "    margins=True,\n",
        "    margins_name=\"Total\"\n",
        ")\n",
        "\n",
        "print(\"Pivot table with margins (totals):\")\n",
        "pivot_with_margins"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a49dfc98",
      "metadata": {
        "id": "a49dfc98"
      },
      "source": [
        "- margins=True\n",
        "Adds totals: both row totals and column totals.\n",
        "- margins_name=\"Total\"\n",
        "Names the total row/column \"Total\" instead of the default \"All\"."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7f228ccb",
      "metadata": {
        "id": "7f228ccb"
      },
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}